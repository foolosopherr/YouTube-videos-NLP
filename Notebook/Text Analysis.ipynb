{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "112c9417-6889-4a1f-be62-8e92b2f26b14",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bacc9ad2-90df-42b7-acfa-b7abe10f9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os \n",
    "import re \n",
    "import string \n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Text Processing Library \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "from gensim import utils\n",
    "import streamlit as st\n",
    "import pprint\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import warnings\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from pathlib import Path\n",
    "from spacy.matcher import PhraseMatcher, Matcher\n",
    "from spacy.tokens import Span\n",
    "import tempfile\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "# Data Visualisation \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import spacy_streamlit\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b42df27-8773-4d73-bd72-f65c3591f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.read_csv('data/Aggregated_Metrics_By_Video.csv', usecols=['Video title']).iloc[1:]\n",
    "titles = titles['Video title'].values\n",
    "text = '; '.join(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03de2a5-ace1-4ceb-bb95-bb0b568822a0",
   "metadata": {},
   "source": [
    "# Text cleaning function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cec8bda-c88f-4c33-adf3-27dda0bd6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function \n",
    "def clean_text(text, STOPWORDS):\n",
    "    '''\n",
    "        Function which returns a clean text \n",
    "    '''    \n",
    "    # Lower case \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    \n",
    "    # Replace \\n and \\t functions \n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Remove punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove Stopwords and Lemmatise the data\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split() if word not in STOPWORDS]\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae22fc-15b1-4cfa-b6f8-f460dbec437f",
   "metadata": {},
   "source": [
    "# Create a word cloud function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "94a3ce1a-99b2-41ce-b5e4-05db1ce01e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word cloud function \n",
    "def create_wordcloud(text, STOPWORDS, image_path = None):\n",
    "    '''\n",
    "    Pass a string to the function and output a word cloud\n",
    "    \n",
    "    ARGS \n",
    "    text: The text for wordcloud\n",
    "    image_path (optional): The image mask with a white background (default None)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # st.write('Creating Word Cloud..')\n",
    "    \n",
    "    text = clean_text(text, STOPWORDS)\n",
    "    \n",
    "    if image_path == None:\n",
    "        \n",
    "        # Generate the word cloud\n",
    "        wordcloud = WordCloud(width = 1200, height = 1200, \n",
    "                    background_color ='white', \n",
    "                    stopwords = STOPWORDS, \n",
    "                    min_font_size = 8).generate(text) \n",
    "    \n",
    "    else:\n",
    "        mask = np.array(Image.open(image_path))\n",
    "        wordcloud = WordCloud(width = 1200, height = 1200, \n",
    "                    background_color ='white', \n",
    "                    stopwords = STOPWORDS,\n",
    "                    mask=mask,\n",
    "                    min_font_size = 8).generate(text) \n",
    "    \n",
    "    # plot the WordCloud image                        \n",
    "    plt.figure(figsize = (20, 20), facecolor = None) \n",
    "    plt.imshow(wordcloud, interpolation = 'nearest') \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e785ff8-e4a8-4ac4-ab5c-aa63c9c8e68c",
   "metadata": {},
   "source": [
    "# Function to plot the ngrams based on n and top k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "baf89d12-942c-49d6-9d55-466e1e0f672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the ngrams based on n and top k value\n",
    "def plot_ngrams(text, STOPWORDS, n=2, topk=15):\n",
    "    '''\n",
    "    Function to plot the most commonly occuring n-grams in bar plots \n",
    "    \n",
    "    ARGS\n",
    "        text: data to be enterred\n",
    "        n: n-gram parameters\n",
    "        topk: the top k phrases to be displayed\n",
    "\n",
    "    '''\n",
    "\n",
    "    st.write('Creating N-Gram Plot..')\n",
    "\n",
    "    text = clean_text(text, STOPWORDS)\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # get the ngrams \n",
    "    ngram_phrases = ngrams(tokens, n)\n",
    "    \n",
    "    # Get the most common ones \n",
    "    most_common = Counter(ngram_phrases).most_common(topk)\n",
    "    \n",
    "    # Make word and count lists \n",
    "    words, counts = [], []\n",
    "    for phrase, count in most_common:\n",
    "        word = ' '.join(phrase)\n",
    "        words.append(word)\n",
    "        counts.append(count)\n",
    "    \n",
    "    # Plot the barplot \n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # title = \"Most Common \" + str(n) + \"-grams in the text\"\n",
    "    # plt.title(title)\n",
    "    # ax = plt.bar(words, counts)\n",
    "    # plt.xlabel(\"n-grams found in the text\")\n",
    "    # plt.ylabel(\"Ngram frequencies\")\n",
    "    # plt.xticks(rotation=90)\n",
    "    # plt.show()\n",
    "    \n",
    "    fig = px.histogram(x=counts, y=words, labels={'x':'N-gram frequences', 'y':'N-grams in the text'}, \n",
    "                       title=f\"Most Common {n}-grams in the text\", height=40*len(words), log_x=True)\n",
    "    fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493ba66-c7fb-4d70-b108-a48e2e1445c0",
   "metadata": {},
   "source": [
    "# Function to return POS tags of a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cc2beff8-227c-41ee-9996-5f4beddadf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return POS tags of a sentence \n",
    "def pos_tagger(s):\n",
    "    \n",
    "    # Define the tag dictionary \n",
    "    output = ''\n",
    "    \n",
    "    # Remove punctuations\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    tagged_sentence = nltk.pos_tag(nltk.word_tokenize(s))\n",
    "    for tag in tagged_sentence:\n",
    "        out = tag[0] + ' ---> ' + tag[1] + '\\n'#'<br>'\n",
    "        output += out\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3a6d32a1-4b3a-4661-9c4c-4edfd22d9b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')\n",
    "STOPWORDS += ['feat', 'ft', 'ep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "13e2549f-17c3-43f4-a9d4-0f3a602bc087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How ---> WRB\n",
      "I ---> PRP\n",
      "Would ---> VBP\n",
      "Learn ---> NNP\n",
      "Data ---> NNP\n",
      "Science ---> NNP\n",
      "If ---> IN\n",
      "I ---> PRP\n",
      "Had ---> VBD\n",
      "to ---> TO\n",
      "Start ---> NNP\n",
      "Over ---> NNP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pos_tagger(titles[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13adcde0-ce8e-4df7-ac44-67e578975c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735f061-6a92-446f-87e8-3e9d5450a4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "857970f990130bbcaee778cf1846f7875676d945310dca1379fe4b5ef3d258a5"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
